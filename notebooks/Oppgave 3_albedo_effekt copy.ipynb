{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albeno effekt\n",
    "---\n",
    "På bakgrunn av hva vi lærte i oppgave 2 rundt datasettet har vi funnet ut:      \n",
    "- Alpene er bra for å se på snøsmelting.\n",
    "- At 21 juni er bra for å se på snøsmelting fra år til år, siden solen er på sitt sterkeste da.\n",
    "- At AL-BB-DH passer vår oppgave best ved at vi ser på et tidspunkt med lite skydekke.\n",
    "- At AL-BB-DH-ERR gir også best data over de 21 årene, ved å sammenligne år til år. \n",
    "\n",
    "Kode 1 filtrer informasjonen ovenfor inn i en csv og komprimerer fil plasseringen til de orginale netcdf filene på 400MB til csv filer på 17MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kode 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode 1\n",
    "\n",
    "Denne koden koprimer dataen vi trenger til csv slikt at vi kan bruke sql for å undersøke datasettet og videre bruk.\n",
    "\n",
    "Lagrer dataen i \"data\" med navnet csv_albedo_effekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2004.csv\n",
      "Data for 2005 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2005.csv\n",
      "Data for 2006 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2006.csv\n",
      "Data for 2007 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2007.csv\n",
      "Data for 2008 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2008.csv\n",
      "Data for 2009 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2009.csv\n",
      "Data for 2010 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2010.csv\n",
      "Data for 2011 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2011.csv\n",
      "Data for 2012 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2012.csv\n",
      "Data for 2013 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2013.csv\n",
      "Data for 2014 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2014.csv\n",
      "Data for 2015 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2015.csv\n",
      "Data for 2016 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2016.csv\n",
      "Data for 2017 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2017.csv\n",
      "Data for 2018 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2018.csv\n",
      "Data for 2019 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2019.csv\n",
      "Data for 2020 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2020.csv\n",
      "Data for 2021 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2021.csv\n",
      "Data for 2022 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2022.csv\n",
      "Data for 2023 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2023.csv\n",
      "Data for 2024 lagret som ..\\data\\csv_albedo_effekt\\Albedo effekt 2024.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Lat og lon for alpene\n",
    "y_min, y_max = 640, 715\n",
    "x_min, x_max = 1700, 1900\n",
    "\n",
    "# Fil plassering csv\n",
    "csv_folder = os.path.join(\"..\", \"data\", \"csv_albedo_effekt\")\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "# For løkke fra årene fra 2004 til 2024\n",
    "for year in range(2004, 2025):\n",
    "    # Filnavn og filsti.\n",
    "    file_name = f\"NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_{year}06250000.nc\"\n",
    "    file_path = os.path.join(\"..\", \"data\", \"albedo_effekt_data\", file_name)\n",
    "    \n",
    "    # Åpne NetCDF-filen\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    \n",
    "    # Utsnitt av datasettet for å fokusere på regionen av interesse\n",
    "    ds_utsnitt = ds.isel(lat=slice(y_min, y_max), lon=slice(x_min, x_max))\n",
    "    \n",
    "    # Ønskede variabler: AL-BB-DH, AL-BB-DH-ERR og quality_flag\n",
    "    variables = [\"AL-BB-DH\", \"AL-BB-DH-ERR\", \"quality_flag\"]\n",
    "    \n",
    "    # Konverter de valgte variablene til en DataFrame\n",
    "    df = ds_utsnitt[variables].to_dataframe().reset_index()\n",
    "    \n",
    "    # Sett sammen CSV-filnavnet med årstall\n",
    "    csv_file_name = f\"Albedo effekt {year}.csv\"\n",
    "    csv_file_path = os.path.join(csv_folder, csv_file_name)\n",
    "    \n",
    "    # Lagre DataFrame til CSV\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data for {year} lagret som {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode 2\n",
    "I koden undersøker vi data kordinater som gir nøyaktig informasjon i alle de 21 årene.  \n",
    "Vi bruker : \n",
    "Query, fra pandassql  \n",
    "List comprehension for years og coords   \n",
    "Og en Iterator i filtered_coords\n",
    "\n",
    "Totalt antall områder med feil < 0.01 (1% feil) i alle år: 11573 kordinater.    \n",
    "Koordinatene med best data lagret i ..\\data\\csv_albedo_effekt\\data_m-lavfeilmargin.csv\n",
    "\n",
    "### Kommentar\n",
    "Ved visualiseringen i mappe 2 kan vi nå velge kordinater fra denne nye csv filen, med høy nøyaktighet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004: 12691 områder med feil < 0.01\n",
      "2005: 13254 områder med feil < 0.01\n",
      "2006: 13553 områder med feil < 0.01\n",
      "2007: 13099 områder med feil < 0.01\n",
      "2008: 13365 områder med feil < 0.01\n",
      "2009: 12861 områder med feil < 0.01\n",
      "2010: 13376 områder med feil < 0.01\n",
      "2011: 13511 områder med feil < 0.01\n",
      "2012: 13219 områder med feil < 0.01\n",
      "2013: 12134 områder med feil < 0.01\n",
      "2014: 12806 områder med feil < 0.01\n",
      "2015: 13434 områder med feil < 0.01\n",
      "2016: 13150 områder med feil < 0.01\n",
      "2017: 13455 områder med feil < 0.01\n",
      "2018: 13024 områder med feil < 0.01\n",
      "2019: 13281 områder med feil < 0.01\n",
      "2020: 13410 områder med feil < 0.01\n",
      "2021: 12911 områder med feil < 0.01\n",
      "2022: 13637 områder med feil < 0.01\n",
      "2023: 13322 områder med feil < 0.01\n",
      "2024: 12566 områder med feil < 0.01\n",
      "\n",
      "Totalt antall områder med feil < 0.01 i alle år: 11573\n",
      "Koordinatene med best data lagret i ..\\data\\csv_albedo_effekt\\data_m-lavfeilmargin.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "# Fil path til CSV-filene\n",
    "csv_folder = os.path.join(\"..\", \"data\", \"csv_albedo_effekt\")\n",
    "\n",
    "# Liste over årstall\n",
    "years = [year for year in range(2004, 2025)]\n",
    "\n",
    "# Variabel for å lagre de felles kvalifiserte koordinatene (lat, lon)\n",
    "qualified_coords = None\n",
    "\n",
    "# Funksjon som gir en iterator over filtrerte koordinater fra en fil\n",
    "def filtered_coords(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # SQL-spørring for å hente ut lat og lon med feil < 0.01\n",
    "    query = \"\"\"\n",
    "    SELECT lat, lon\n",
    "    FROM df\n",
    "    WHERE `AL-BB-DH-ERR` < 0.01\n",
    "    \"\"\"\n",
    "    result = psql.sqldf(query, locals())\n",
    "\n",
    "    # Bruk en generator for å levere koordinater en etter en \n",
    "    for lat, lon in zip(result[\"lat\"], result[\"lon\"]):\n",
    "        yield lat, lon\n",
    "\n",
    "# Samle alle kvalifiserte koordinater fra hvert år\n",
    "for year in years:\n",
    "    file_path = os.path.join(csv_folder, f\"Albedo effekt {year}.csv\")\n",
    "\n",
    "    # Bygger settet med koordinater\n",
    "    coords = {coord for coord in fetch_filtered_coords(file_path)}\n",
    "    print(f\"{year}: {len(coords)} områder med feil < 0.01\")\n",
    "    \n",
    "    # Finner felles koordinater mellom år\n",
    "    qualified_coords = coords if qualified_coords is None else qualified_coords.intersection(coords)\n",
    "\n",
    "print(f\"\\nTotalt antall områder med feil < 0.01 i alle år: {len(qualified_coords)}\")\n",
    "\n",
    "# Lagre resultatet i en CSV-fil i samme folder\n",
    "output_file = os.path.join(csv_folder, \"data_m-lavfeilmargin.csv\")\n",
    "df_result = pd.DataFrame(list(qualified_coords), columns=[\"lat\", \"lon\"])\n",
    "df_result.to_csv(output_file, index=False)\n",
    "print(f\"Koordinatene med best data lagret i {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Oppgave 3 konklusjon\n",
    "\n",
    "Vi har filtrert dataen ved hjelp av list comprehensions, iteratorer og Pandas SQL. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
