{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrerer ut datasett med for liten datamengde. Kan justeres i \"terskel\" variabelen.\n",
    "Dette er en måte å filtrere ut datasett som inneholder lite til ingen data. Gjør dette fordi vi ønsker å finne ut hvilket datasett som er gunstig å undersøke videre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Definer en terskel for tileCount\n",
    "terskel = 100000\n",
    "\n",
    "\n",
    "# Juster Pandas-opsjoner for å vise flere rader og kolonner om ønskelig\n",
    "pd.set_option('display.max_rows', 374)      # Viser opptil 374 rader\n",
    "pd.set_option('display.max_columns', None) # Viser alle kolonner\n",
    "pd.set_option('display.width', None)       # Unngå avkorting av kolonner\n",
    "\n",
    "# Sett base-URL for API-et\n",
    "base_url = \"https://sealevel-nexus.jpl.nasa.gov\"\n",
    "endpoint = \"/list\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # data er en liste med ordbøker (datasetter)\n",
    "    data = response.json()\n",
    "\n",
    "    # Konverter data til en DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filtrer ut rader med tilecount under terskelen\n",
    "    df_filtrert = df[df[\"tileCount\"] >= terskel]\n",
    "\n",
    "    # Skriv ut filtrert DataFrame i tabellform uten indeks\n",
    "    print(\"Filtrert tabell (tileCount >= {}):\".format(terskel))\n",
    "    print(df_filtrert.to_string(index=False))\n",
    "else:\n",
    "    print(\"Feil ved henting av datasett:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrerer ut datasettene som ikke inneholder SSH (Sea Surface Height) og som ikke er over datamengde terskelen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Definer terskel for tileCount\n",
    "terskel = 10000\n",
    "\n",
    "# Juster Pandas-opsjoner for å vise alle kolonner og flere rader i en bred tabell\n",
    "pd.set_option('display.max_rows', 374)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Sett base-URL og endepunkt for API-et\n",
    "base_url = \"https://sealevel-nexus.jpl.nasa.gov\"\n",
    "endpoint = \"/list\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filtrer ut datasett med tilecount under terskelen\n",
    "    df_filtrert = df[df[\"tileCount\"] >= terskel]\n",
    "\n",
    "    # Velg kun de datasettene som inneholder \"SSH\" i for kolonnen 'shortName'\n",
    "    df_ssh = df_filtrert[df_filtrert[\"shortName\"].str.contains(\"SSH\", case=False, na=False)]\n",
    "\n",
    "    # Skriv ut den filtrerte tabellen uten indeks\n",
    "    print(f\"Datasett med tileCount >= {terskel} og som inneholder 'SSH':\")\n",
    "    print(df_ssh.to_string(index=False))\n",
    "else:\n",
    "    print(\"Feil ved henting av datasett:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finner SSH datasettene i API-en ved bruk av list comprehensions\n",
    "Dette går gjennom hele datasettet (som er en liste med ordbøker) og lager en ny liste som kun inneholder de datasettene med \"SSH\" i shortName. Det er en effektiv og lesbar måte å filtrere og hente ut relevante datasett på. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Hent data fra API-et\n",
    "\n",
    "base_url = \"https://sealevel-nexus.jpl.nasa.gov\"\n",
    "endpoint = \"/list\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    print(\"Feil ved henting av datasett:\", response.status_code)\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Bruker list comprehension for å hente ut SSH-datasett\n",
    "ssh_datasets = [d[\"shortName\"] for d in data if \"SSH\" in d.get(\"shortName\", \"\")]\n",
    "print(\"Liste over datasettnavn som inneholder 'SSH':\")\n",
    "print(ssh_datasets)\n",
    "print(\"\\n-----------------------------------------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrerer ut datasett som ikke inneholder \"SSH\" ved bruk av itererasjoner. \n",
    "Regner ut differansen på antall år målingene har blitt tatt. Deretter kan vi se videre på egenskapene til de ulike datasettene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# Hent data fra API-et\n",
    "\n",
    "base_url = \"https://sealevel-nexus.jpl.nasa.gov\"\n",
    "endpoint = \"/list\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    print(\"Feil ved henting av datasett:\", response.status_code)\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Konverter iso_start og iso_end til datetime, og beregn varighet i år\n",
    "df[\"iso_start_dt\"] = pd.to_datetime(df[\"iso_start\"])\n",
    "df[\"iso_end_dt\"]   = pd.to_datetime(df[\"iso_end\"])\n",
    "\n",
    "# Tar differansen i dager og deler på 365.25 for å få en tilnærming i år\n",
    "df[\"duration_years\"] = (df[\"iso_end_dt\"] - df[\"iso_start_dt\"]).dt.days / 365.25\n",
    "\n",
    "\n",
    "# 2. Bruker iterasjoner for å skrive ut egenskaper\n",
    "print(\"Detaljer om SSH-datasettene (ved iterasjoner):\")\n",
    "for index, row in df.iterrows():\n",
    "    if \"SSH\" in row[\"shortName\"]:\n",
    "        print(f\"Index {index}: shortName = {row['shortName']}, \"\n",
    "              f\"title = {row.get('title')}, \"\n",
    "              f\"tileCount = {row.get('tileCount')}, \"\n",
    "              f\"duration_years = {row.get('duration_years'):.2f}\")\n",
    "print(\"\\n-----------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anlyserer SSH datasettene ved bruk av Pandas SQL\n",
    "Pandasql lar deg bruke SQL-spørringer direkte på Pandas DataFrames. Dette kan gjøre det enklere og mer intuitivt å jobbe med data for de som er godt kjent med SQL. I stedet for å måtte bruke flere forskjellige Pandas-funksjoner når du skal filtrere, sortere eller gruppere data, kan du gjøre alt med én SQL-setning. Dette gir en mer oversiktlig kode, spesielt når du gjør kompliserte operasjoner. I tillegg gjør Pandasql det lettere å kombinere flere DataFrames med JOIN, noe som ofte er litt vanskeligere med vanlige Pandas-funksjoner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH-datasett fra SQL-spørring:\n",
      "                               shortName                                    title  tileCount                iso_start                  iso_end  duration_years\n",
      "NASA_SSH_REF_SIMPLE_GRID_V1_Monthly_clim NASA_SSH_REF_SIMPLE_GRID_V1_Monthly_clim       2604 1970-01-16T00:00:00+0000 1970-12-16T00:00:00+0000        0.914442\n",
      "      SSHIBC_ECCO_version4_release4_clim       SSHIBC_ECCO_version4_release4_clim       3024 1970-01-16T00:00:00+0000 1970-12-16T00:00:00+0000        0.914442\n",
      "    SSHNOIBC_ECCO_version4_release4_clim     SSHNOIBC_ECCO_version4_release4_clim       3024 1970-01-16T00:00:00+0000 1970-12-16T00:00:00+0000        0.914442\n",
      "         SSH_ECCO_version4_release4_clim          SSH_ECCO_version4_release4_clim       3024 1970-01-16T00:00:00+0000 1970-12-16T00:00:00+0000        0.914442\n",
      "           SSHIBC_ECCO_version4_release4            SSHIBC_ECCO_version4_release4      78624 1992-01-16T18:00:00+0000 2017-12-16T06:00:00+0000       25.915127\n",
      "         SSHNOIBC_ECCO_version4_release4          SSHNOIBC_ECCO_version4_release4      78624 1992-01-16T18:00:00+0000 2017-12-16T06:00:00+0000       25.915127\n",
      "              SSH_ECCO_version4_release4               SSH_ECCO_version4_release4      78624 1992-01-16T18:00:00+0000 2017-12-16T06:00:00+0000       25.915127\n",
      "     NASA_SSH_REF_SIMPLE_GRID_V1_Monthly      NASA_SSH_REF_SIMPLE_GRID_V1_Monthly      83381 1992-10-01T00:00:00+0000 2024-11-01T00:00:00+0000       32.084873\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pandasql import sqldf  \n",
    "\n",
    "# API-endepunkt og URL\n",
    "base_url = \"https://sealevel-nexus.jpl.nasa.gov\"\n",
    "endpoint = \"/list\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "# Hent data fra API-et\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df_datasets = pd.DataFrame(data)\n",
    "else:\n",
    "    print(f\"Feil ved henting av datasett: {response.status_code} - {response.text}\")\n",
    "    exit(1)\n",
    "\n",
    "# Konverter datokolonner til datetime-format for videre beregning\n",
    "df_datasets[\"iso_start_dt\"] = pd.to_datetime(df_datasets[\"iso_start\"])\n",
    "df_datasets[\"iso_end_dt\"] = pd.to_datetime(df_datasets[\"iso_end\"])\n",
    "\n",
    "# Funksjon for enklere SQL-spørringer\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "# SQL-spørring for å hente ut SSH-datasett og varighet\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        shortName,\n",
    "        title,\n",
    "        tileCount,\n",
    "        iso_start,\n",
    "        iso_end,\n",
    "        (julianday(iso_end_dt) - julianday(iso_start_dt)) / 365.25 AS duration_years\n",
    "    FROM df_datasets\n",
    "    WHERE shortName LIKE '%SSH%'\n",
    "    ORDER BY iso_start_dt ASC;\n",
    "\"\"\"\n",
    "\n",
    "# Utfør SQL-spørring\n",
    "df_ssh_sql = pysqldf(query)\n",
    "\n",
    "# Vis resultatet\n",
    "print(\"SSH-datasett fra SQL-spørring:\")\n",
    "print(df_ssh_sql.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velger å se på \"NASA_SSH_REF_SIMPLE_GRID_V1_Monthly\" videre.\n",
    "Ser i tabellen ovenfor at \"NASA_SSH_REF_SIMPLE_GRID_V1_Monthly\" har største mengden data og målinger over den lengste perioden. Derfor vil det være naturlig å jobbe med dette datasettet videre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setter opp dataen i \"NASA_SSH_REF_SIMPLE_GRID_V1_Monthly\" i en tabell.\n",
    " Det kan fort oppstå manglende verdier eller målingsfeil i slike datasett. Dette løser vi ved å lage et intervall for realistiske målinger og tester \"mean\" verdiene opp mot intervallet. Deretter teller vi antall ganger vi møter verdier utenfor intervallet eller vi møter en tom verdi. Slik finner vi antall feilverdier og ser om dataen er klar for videre analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall registreringer mottatt: 386\n",
      "\n",
      "--- Utdrag av datasettet (første 386 radene) ---\n",
      "          min       max      mean     cnt       std        time  \\\n",
      "0   -0.388882  0.431853 -0.000171  145539  0.056767   717897600   \n",
      "1   -0.366509  0.296866 -0.004225  147346  0.050972   720576000   \n",
      "2   -0.311839  0.319928 -0.012979  147965  0.050031   723168000   \n",
      "3   -0.330625  0.358001 -0.018975  147545  0.055296   725846400   \n",
      "4   -0.362726  0.390943 -0.020470  147413  0.059630   728524800   \n",
      "..        ...       ...       ...     ...       ...         ...   \n",
      "381 -0.542817  0.558163  0.079627  146544  0.053102  1719792000   \n",
      "382 -0.356477  0.744147  0.082227  145662  0.062035  1722470400   \n",
      "383 -0.362203  0.837300  0.086179  145581  0.064875  1725148800   \n",
      "384 -0.433927  0.828580  0.092794  145621  0.064465  1727740800   \n",
      "385 -0.490822  0.806355  0.093230  146428  0.061592  1730419200   \n",
      "\n",
      "                     iso_time  meanLowPass  maxLowPass  minLowPass  ds  \n",
      "0    1992-10-01T00:00:00+0000    -0.000041    0.431830   -0.388207   0  \n",
      "1    1992-11-01T00:00:00+0000    -0.002036    0.414729   -0.385676   0  \n",
      "2    1992-12-01T00:00:00+0000    -0.003999    0.398016   -0.382892   0  \n",
      "3    1993-01-01T00:00:00+0000    -0.005899    0.381920   -0.379893   0  \n",
      "4    1993-02-01T00:00:00+0000    -0.007707    0.366658   -0.376721   0  \n",
      "..                        ...          ...         ...         ...  ..  \n",
      "381  2024-07-01T00:00:00+0000     0.076271    0.607618   -0.559791   0  \n",
      "382  2024-08-01T00:00:00+0000     0.076272    0.607621   -0.559796   0  \n",
      "383  2024-09-01T00:00:00+0000     0.076273    0.607624   -0.559799   0  \n",
      "384  2024-10-01T00:00:00+0000     0.076274    0.607625   -0.559800   0  \n",
      "385  2024-11-01T00:00:00+0000     0.076274    0.607626   -0.559801   0  \n",
      "\n",
      "[386 rows x 11 columns]\n",
      "\n",
      "Antall usaklige verdier i havnivådata: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "base_url = \"https://sealevel-nexus.jpl.nasa.gov\"\n",
    "endpoint = \"/timeSeriesSpark\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "params = {\n",
    "    \"ds\": \"NASA_SSH_REF_SIMPLE_GRID_V1_Monthly\",\n",
    "    \"b\": \"-180.0,-90.0,180.0,90.0\",\n",
    "    \"startTime\": \"1992-01-01T00:00:00Z\",\n",
    "    \"endTime\": \"2025-01-01T00:00:00Z\",\n",
    "    \"output\": \"JSON\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    ts_data = response.json()\n",
    "else:\n",
    "    print(\"Feil ved henting av tidsseriedata:\", response.status_code, response.text)\n",
    "    ts_data = None\n",
    "\n",
    "if ts_data and \"data\" in ts_data:\n",
    "    # ts_data[\"data\"] er en liste med mange \"sub-lister\",\n",
    "    # hvor hver sub-liste inneholder ordbøker med felter som 'mean' og 'iso_time'.\n",
    "    data_list_of_lists = ts_data[\"data\"]\n",
    "\n",
    "    # Slå sammen alle underlister til én flat liste med ordbøker\n",
    "    all_records = []\n",
    "    for sublist in data_list_of_lists:\n",
    "        all_records.extend(sublist)\n",
    "\n",
    "    print(f\"Antall registreringer mottatt: {len(all_records)}\")\n",
    "\n",
    "    # Konverter til Pandas-DataFrame for å få en oversiktlig tabell\n",
    "    df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Ser de utvalgte radene i DataFrame\n",
    "    print(\"\\n--- Utdrag av datasettet (første 386 radene) ---\")\n",
    "    print(df.head(386))\n",
    "\n",
    "else:\n",
    "    print(\"Responsen har ikke den forventede strukturen eller er tom.\")\n",
    "\n",
    "# Definerer det gyldige intervallet for havnivåverdier (kan justeres nedenfor)\n",
    "min_valid = -0.1\n",
    "max_valid = 0.1\n",
    "\n",
    "# Sjekk at 'mean'-kolonnen finnes i DataFrame\n",
    "if 'mean' in df.columns:\n",
    "    # Finner manglende (NaN) verdier eller verdier utenfor intervallet\n",
    "    invalid_mask = df['mean'].isna() | (df['mean'] < min_valid) | (df['mean'] > max_valid)\n",
    "    \n",
    "    # Teller antall usaklige verdier\n",
    "    invalid_count = invalid_mask.sum()\n",
    "    \n",
    "    print(\"\\nAntall usaklige verdier i havnivådata:\", invalid_count)\n",
    "else:\n",
    "    print(\"Kolonnen 'mean' finnes ikke i datasettet.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
