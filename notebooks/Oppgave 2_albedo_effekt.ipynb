{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Albeno effekt\n",
    "---\n",
    "Vi har idendifisert **EUMETSAT**, The European Organisation for the Exploitation of Meteorological Satellites som en relevant kilde med høy **kildeautoritet, datakvalitet tilgjenglighet og brukervennlighet**. \n",
    "\n",
    "EUMETSAT:\n",
    "- Er en velkjent organisasjon og leverer presise data til nasjonale metrologiske institutt. (**Kildeautoritet**)\n",
    "- De har tilhørende feilmarginer til vær enkel data i vært eneste dataset. Målingene er basert på 1 måneds historikk som gjør dataen mer pålitelig. (**Datakvalitet**)\n",
    "- De har egne dokumenter for bruk og følger standarisert dataformar som de aller fleste metroloiske institutt.\n",
    " (**Tilgjenglighet**)\n",
    "- Dataformatet NETCDF4 gir stor frihet i bruk. (**Brukervennlighet**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kode 1\n",
    "**Kommentarer:**\n",
    "\n",
    "I koden nedenfor  bruker vi intigrerte pyton bibloteker og request. \n",
    "\n",
    "Vi har laget en bruker på EUMETSAT som student og bruker username og passord for å sende en HTTP-forespørsel/API-forespørsel for få tilgang til data\n",
    "\n",
    "Filene som lastes ned blir så plassert i felles data-folderen \"data\" og inn i egen albedo_effekt_data folder. Dette gjør vi for å ha fil- og katalogadministrasjon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Brukernavn og passord for autentisering\n",
    "username = 'matsgulbrandsen'\n",
    "password = 'V2.ShXbmWRZ!S9a'\n",
    "\n",
    "# Start- og sluttdato\n",
    "start_date = datetime(2004, 6, 25)  # 4 dager etter sommersolverv, \n",
    "end_date = datetime(2024, 6, 25)    # 21. juni siden det er dette EUMETSAT tilbyr\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/MDALv2/NETCDF\"\n",
    "\n",
    "# Sett download_folder til å lagre filene i data-mappen\n",
    "download_folder = os.path.join(\"..\", \"data\", \"netcdf_downloads\")\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# Funksjon for å laste ned filene\n",
    "def download_file(current_date):\n",
    "    # Formatter datoene riktig\n",
    "    date_path = current_date.strftime(\"%Y/%m/%d\")  # gjør om dato til tekst Eks: 2004/06/21\n",
    "    date_filename = current_date.strftime(\"%Y%m%d0000\")  #-||- Eks: 200406210000\n",
    "\n",
    "    # Full URL til filen\n",
    "    file_url = f\"{base_url}/{date_path}/NETCDF4_LSASAF_MSG_ALBEDOv2_MSG-Disk_{date_filename}.nc\"\n",
    "\n",
    "    # Lokalt filnavn\n",
    "    file_name = f\"NETCDF4_LSASAF_MSG_ALBEDOv2_MSG-Disk_{date_filename}.nc\"\n",
    "    file_path = os.path.join(download_folder, file_name)\n",
    "\n",
    "    try:\n",
    "        # Bruker Basic Authentication for å laste ned filen\n",
    "        response = requests.get(file_url, auth=HTTPBasicAuth(username, password))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Lastet ned: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Feil {response.status_code}: Kan ikke laste ned {file_url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Feil ved nedlasting: {e}\")\n",
    "\n",
    "# Last ned filer én etter én\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    download_file(current_date)  # Kall funksjonen direkte uten parallellitet\n",
    "    current_date = current_date.replace(year=current_date.year + 1) # Laster ned årlige filer\n",
    "\n",
    "\n",
    "print(\"Alle tilgjengelige filer er forsøkt lastet ned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200406250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200506250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200606250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200706250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200806250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200906250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201006250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201106250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201206250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201306250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201406250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201506250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201606250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201706250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201806250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_201906250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_202006250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_202106250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_202206250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_202306250000.nc\n",
      "Lastet ned: NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_202406250000.nc\n",
      "Alle tilgjengelige filer er forsøkt lastet ned.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Brukernavn og passord for autentisering\n",
    "username = 'matsgulbrandsen'\n",
    "password = 'V2.ShXbmWRZ!S9a'\n",
    "\n",
    "# Start- og sluttdato\n",
    "start_date = datetime(2004, 6, 25)  # 25. juni er 4 dager etter sommersolverv\n",
    "end_date = datetime(2024, 6, 25)\n",
    "\n",
    "# Felles Base URL for albedo effekt data\n",
    "base_url = \"https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/MTALv2/NETCDF\"\n",
    "\n",
    "# Sett download_folder til å lagre filene i albedo_effekt_data-mappen\n",
    "download_folder = os.path.join(\"..\", \"data\", \"albedo_effekt_data\")\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# Funksjon for å laste ned filene\n",
    "def download_file(current_date):\n",
    "    # Formatter datoene riktig\n",
    "    date_path = current_date.strftime(\"%Y/%m/%d\")  # Eks: 2004/06/25\n",
    "    date_filename = current_date.strftime(\"%Y%m%d0000\")  # Eks: 200406250000\n",
    "\n",
    "    # Full URL til filen\n",
    "    file_url = f\"{base_url}/{date_path}/NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_{date_filename}.nc\"\n",
    "\n",
    "    # Lokalt filnavn\n",
    "    file_name = f\"NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_{date_filename}.nc\"\n",
    "    file_path = os.path.join(download_folder, file_name)\n",
    "\n",
    "    try:\n",
    "        # Bruker Basic Authentication for å laste ned filen\n",
    "        response = requests.get(file_url, auth=HTTPBasicAuth(username, password))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Lastet ned: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Feil {response.status_code}: Kan ikke laste ned {file_url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Feil ved nedlasting: {e}\")\n",
    "\n",
    "# Last ned filer én etter én (årlig nedlasting)\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    download_file(current_date)\n",
    "    current_date = current_date.replace(year=current_date.year + 1)\n",
    "\n",
    "print(\"Alle tilgjengelige filer er forsøkt lastet ned.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Utforskning av data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode 2\n",
    "Åpner dataen og ser på hvilke variabler den inneholder\n",
    "\n",
    "### Konklusjon av data\n",
    "\n",
    "Dataen har 3 dimmensjoner, men egt bare 2 siden den ser på 1 tidsøyeblikk per dag.\n",
    "\n",
    "Ved undersøkelse av de ulike variablene:\n",
    "\n",
    "Finner vi ut at AL-BB-BH er bedre for en årlig analyse, men siden vi ser på sommersolverv og vi kan filtrere ut dårlig data. Konkluderer vi AL-BB-DH som best siden den gir bedre data for skyfrie dager.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "\n",
    "# Åpne en NetCDF-fil\n",
    "file_path = '../data/albedo_effekt_data/NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_200406250000.nc'\n",
    "dataset = netCDF4.Dataset(file_path, 'r')\n",
    "# Skriv ut alle tilgjengelige variabler i datasetet\n",
    "print(dataset.variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode 3\n",
    "\n",
    "Denne koden koprimer dataen vi trenger basert på kode 2 sin informasjon til csv slikt at vi kan bruke sql for å undersøke data.\n",
    "\n",
    "Lagrer dataen i \"data\" med navnet csv_albedo_effekt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Lat og lon for alpene\n",
    "y_min, y_max = 640, 715\n",
    "x_min, x_max = 1700, 1900\n",
    "\n",
    "# Fil plassering csv\n",
    "csv_folder = os.path.join(\"..\", \"data\", \"csv_albedo_effekt\")\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "# For løkke fra årene fra 2004 til 2024\n",
    "for year in range(2004, 2025):\n",
    "    # Filnavn og filsti.\n",
    "    file_name = f\"NETCDF4_LSASAF_MSG_ALBEDO-D10v2_MSG-Disk_{year}06250000.nc\"\n",
    "    file_path = os.path.join(\"..\", \"data\", \"albedo_effekt_data\", file_name)\n",
    "    \n",
    "    # Åpne NetCDF-filen\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    \n",
    "    # Utsnitt av datasettet for å fokusere på regionen av interesse\n",
    "    ds_utsnitt = ds.isel(lat=slice(y_min, y_max), lon=slice(x_min, x_max))\n",
    "    \n",
    "    # Ønskede variabler: AL-BB-DH, AL-BB-DH-ERR og quality_flag\n",
    "    variables = [\"AL-BB-DH\", \"AL-BB-DH-ERR\", \"quality_flag\"]\n",
    "    \n",
    "    # Konverter de valgte variablene til en DataFrame\n",
    "    df = ds_utsnitt[variables].to_dataframe().reset_index()\n",
    "    \n",
    "    # Sett sammen CSV-filnavnet med årstall\n",
    "    csv_file_name = f\"Albedo effekt {year}.csv\"\n",
    "    csv_file_path = os.path.join(csv_folder, csv_file_name)\n",
    "    \n",
    "    # Lagre DataFrame til CSV\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data for {year} lagret som {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode 4\n",
    "I koden undersøker vi data kordinater som gir nøyaktig informasjon i alle de 21 årene.  \n",
    "Vi bruker : \n",
    "Query, fra pandassql  \n",
    "List comprehension for years og coords   \n",
    "Og en Iterator i filtered_coords\n",
    "\n",
    "Totalt antall områder med feil < 0.01 (1% feil) i alle år: 11573 kordinater.    \n",
    "Koordinatene med best data lagret i ..\\data\\csv_albedo_effekt\\data_m-lavfeilmargin.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "# Fil path til CSV-filene\n",
    "csv_folder = os.path.join(\"..\", \"data\", \"csv_albedo_effekt\")\n",
    "\n",
    "# Liste over årstall\n",
    "years = [year for year in range(2004, 2025)]\n",
    "\n",
    "# Variabel for å lagre de felles kvalifiserte koordinatene (lat, lon)\n",
    "qualified_coords = None\n",
    "\n",
    "# Funksjon som gir en iterator over filtrerte koordinater fra en fil\n",
    "def filtered_coords(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # SQL-spørring for å hente ut lat og lon med feil < 0.01\n",
    "    query = \"\"\"\n",
    "    SELECT lat, lon\n",
    "    FROM df\n",
    "    WHERE `AL-BB-DH-ERR` < 0.01\n",
    "    \"\"\"\n",
    "    result = psql.sqldf(query, locals())\n",
    "\n",
    "    # Bruk en generator for å levere koordinater en etter en \n",
    "    for lat, lon in zip(result[\"lat\"], result[\"lon\"]):\n",
    "        yield lat, lon\n",
    "\n",
    "# Samle alle kvalifiserte koordinater fra hvert år\n",
    "for year in years:\n",
    "    file_path = os.path.join(csv_folder, f\"Albedo effekt {year}.csv\")\n",
    "\n",
    "    # Bygger settet med koordinater\n",
    "    coords = {coord for coord in fetch_filtered_coords(file_path)}\n",
    "    print(f\"{year}: {len(coords)} områder med feil < 0.01\")\n",
    "    \n",
    "    # Finner felles koordinater mellom år\n",
    "    qualified_coords = coords if qualified_coords is None else qualified_coords.intersection(coords)\n",
    "\n",
    "print(f\"\\nTotalt antall områder med feil < 0.01 i alle år: {len(qualified_coords)}\")\n",
    "\n",
    "# Lagre resultatet i en CSV-fil i samme folder\n",
    "output_file = os.path.join(csv_folder, \"data_m-lavfeilmargin.csv\")\n",
    "df_result = pd.DataFrame(list(qualified_coords), columns=[\"lat\", \"lon\"])\n",
    "df_result.to_csv(output_file, index=False)\n",
    "print(f\"Koordinatene med best data lagret i {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Oppgave 2 konklusjon\n",
    "\n",
    "Vi har funnet en pålitlig kilde med god datakvalitet, undersøkt dataen ved hjelp av list comprehensions, iteratorer og Pandas SQL og request for å få tilgang til dataen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
